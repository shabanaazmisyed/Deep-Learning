{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"0MPnWgblA6_5"},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, LSTM, Dense"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sSWshszzCAiF"},"outputs":[],"source":["  with open('/content/sharelock.txt', 'r', encoding='utf-8') as file:\n","    text = file.read()"]},{"cell_type":"code","source":["tokenizer = Tokenizer()\n","tokenizer.fit_on_texts([text])\n","total_words = len(tokenizer.word_index) + 1"],"metadata":{"id":"FfqyDkSWjoWT"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nVFeQeZeDvar"},"outputs":[],"source":["input_sequences = []\n","for line in text.split('\\n'):\n","    token_list = tokenizer.texts_to_sequences([line])[0]\n","    for i in range(1, len(token_list)):\n","        n_gram_sequence = token_list[:i+1]\n","        input_sequences.append(n_gram_sequence)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bUOzM8ugD2W8"},"outputs":[],"source":["max_sequence_len = max([len(seq) for seq in input_sequences])\n","input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Oj5dDvN-D8S8"},"outputs":[],"source":["X = input_sequences[:, :-1]\n","y = input_sequences[:, -1]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qHUMcgyYEHIb"},"outputs":[],"source":["y = np.array(tf.keras.utils.to_categorical(y, num_classes=total_words))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1696587825965,"user":{"displayName":"CSE C","userId":"15135267234154746110"},"user_tz":-330},"id":"mEKiTbYiEV67","outputId":"42c81f71-70b8-4272-81f6-3866d8a82d69"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_1 (Embedding)     (None, 7, 100)            900       \n","                                                                 \n"," lstm_1 (LSTM)               (None, 150)               150600    \n","                                                                 \n"," dense_1 (Dense)             (None, 9)                 1359      \n","                                                                 \n","=================================================================\n","Total params: 152859 (597.11 KB)\n","Trainable params: 152859 (597.11 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n"]}],"source":["model = Sequential()\n","model.add(Embedding(total_words, 100, input_length=max_sequence_len-1))\n","model.add(LSTM(150))\n","model.add(Dense(total_words, activation='softmax'))\n","print(model.summary())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3121,"status":"ok","timestamp":1696587831461,"user":{"displayName":"CSE C","userId":"15135267234154746110"},"user_tz":-330},"id":"UnDSBUtmEdQk","outputId":"33e0d2bb-93e6-4d8d-ae3e-5883a2b19128"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","1/1 [==============================] - 3s 3s/step - loss: 2.1933 - accuracy: 0.1429\n","Epoch 2/10\n","1/1 [==============================] - 0s 21ms/step - loss: 2.1810 - accuracy: 0.2857\n","Epoch 3/10\n","1/1 [==============================] - 0s 25ms/step - loss: 2.1683 - accuracy: 0.5714\n","Epoch 4/10\n","1/1 [==============================] - 0s 24ms/step - loss: 2.1551 - accuracy: 0.5714\n","Epoch 5/10\n","1/1 [==============================] - 0s 23ms/step - loss: 2.1409 - accuracy: 0.5714\n","Epoch 6/10\n","1/1 [==============================] - 0s 21ms/step - loss: 2.1256 - accuracy: 0.5714\n","Epoch 7/10\n","1/1 [==============================] - 0s 20ms/step - loss: 2.1086 - accuracy: 0.5714\n","Epoch 8/10\n","1/1 [==============================] - 0s 22ms/step - loss: 2.0897 - accuracy: 0.5714\n","Epoch 9/10\n","1/1 [==============================] - 0s 18ms/step - loss: 2.0684 - accuracy: 0.5714\n","Epoch 10/10\n","1/1 [==============================] - 0s 21ms/step - loss: 2.0441 - accuracy: 0.5714\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x78cbe3ffdf90>"]},"metadata":{},"execution_count":19}],"source":["model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","model.fit(X, y, epochs=10, verbose=1)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3539,"status":"ok","timestamp":1696587842984,"user":{"displayName":"CSE C","userId":"15135267234154746110"},"user_tz":-330},"id":"BUInAo9kNyn0","outputId":"17099447-a371-4732-cd2d-39db40a99754"},"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 437ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 24ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 26ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 38ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 26ms/step\n","hello there! am am am doing fine what you you you you you you am fine you you you you you you am fine you you you you you you am fine you you you you you you am fine you you\n"]}],"source":["seed_text = \"hello there!\"\n","next_words = 40\n","\n","for _ in range(next_words):\n","    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n","    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n","    predicted = np.argmax(model.predict(token_list), axis=-1)\n","    output_word = \"\"\n","    for word, index in tokenizer.word_index.items():\n","        if index == predicted:\n","            output_word = word\n","            break\n","    seed_text += \" \" + output_word\n","\n","print(seed_text)\n"]}],"metadata":{"colab":{"provenance":[{"file_id":"1VJStvddpSslU6i2N_HqIQUzpIC3trTlm","timestamp":1698932375703},{"file_id":"https://github.com/20NN1A12C1/Deep-Learning-lab/blob/main/DLLAB4.ipynb","timestamp":1695981699029}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}